# AuraFlow Environment Configuration Template
# Copy this file to .env and fill in your actual API keys
# IMPORTANT: Never commit .env to version control

# ===== LLM Provider Configuration =====

# Groq API (Free tier available)
# Get key from: https://console.groq.com
GROQ_API_KEY=gsk_your_groq_api_key_here

# Google Gemini API (Free tier available)
# Get key from: https://ai.google.dev
GEMINI_API_KEY=AIza_your_gemini_api_key_here

# OpenAI API (Paid only)
# Get key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk_your_openai_api_key_here

# Which provider to use: groq, gemini, or openai
LLM_PROVIDER=groq

# Model selection (depends on provider)
# Groq: llama-3.1-8b-instant, mixtral-8x7b-32768, gemma-7b-it
# Gemini: gemini-1.5-pro, gemini-1.5-flash, gemini-pro
# OpenAI: gpt-4, gpt-4-turbo, gpt-3.5-turbo
CURRENT_AI_MODEL=llama-3.1-8b-instant

# ===== Memory/Vector Database Configuration =====

# Qdrant settings
MEMORY_BACKEND=qdrant
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=default-api-key
QDRANT_COLLECTION=auraflow_memory

# ===== Application Configuration =====

# Node environment
NODE_ENV=development

# ===== Docker Configuration =====
# For Docker environments, Qdrant runs in a container on the same network
# QDRANT_URL=http://qdrant:6333
